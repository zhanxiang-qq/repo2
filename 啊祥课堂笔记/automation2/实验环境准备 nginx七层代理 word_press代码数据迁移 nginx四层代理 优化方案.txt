1、实验环境准备
	1）环境准备
		vmware管理器：添加 vmnet3，取消DHCP自动分配
		          	          修改真机上 vmnet3 网卡IP为192.168.4.254
	
		proxy：192.168.4.5（vmnet3）
	            	            192.168.2.5（vmnet1，nmcli  connection add con-name ens37 ifname  ens37 type ethernet）

		web1：192.168.2.100（vmnet2）
                                            搭建LNMP动态网站

		web2：192.168.2.200（vmnet2）
	                            搭建LNMP动态网站

	2）web1和web2搭建步骤（两台机器做相同操作）
		yum  -y  install  gcc  pcre-devel  openssl-devel
		tar  -xf  nginx-1.17.6.tar.gz
		cd  nginx-1.17.6
		./configure  --with-http_ssl_module
		make  && make install
		yum  -y install mariadb  mariadb-server  mariadb-devel
		yum  -y install php  php-fpm  php-mysql
		
		vim  /usr/local/nginx/conf/nginx.conf
		localtion  / {
			root  	html;
			index  index.php  index.html  index.htm;
		}
		location ~ \.php$ {
            			root           html;
           			fastcgi_pass   127.0.0.1:9000;
            			fastcgi_index  index.php;
            			include        fastcgi.conf;
        		}
		:wq
		echo  "/usr/local/nginx/sbin/nginx"  >> /etc/rc.local
		chmod  +x  /etc/rc.local
		/usr/local/nginx/sbin/nginx
		systemctl  start  mariadb   php-fpm
		systemctl  enable  mariadb  php-fpm
		iptables  -F
		setenforce  0
		web1上添加网页测试文件：
			vim   /usr/local/nginx/html/test.php
			<?php
			$i="web1";
			echo  $i;
			?>
		web2上添加网页测试文件：	
			vim   /usr/local/nginx/html/test.php
			<?php
			$i="web2";
			echo  $i;
			?>	

	3）客户机分别访问测试web1和web2：
		http://192.168.2.100/test.php
		http://192.168.2.200/test.php


2、Nginx 七层代理
	1）部署代理服务器proxy
		yum  -y  install  gcc  pcre-devel  openssl-devel
		tar  -xf  nginx-1.17.6.tar.gz
		cd  nginx-1.17.6
		./configure  --with-http_ssl_module
		make  && make install
		vim  /usr/local/nginx/conf/nginx.conf
		http  {
			upstream  servers {
				server 192.168.2.100:80;
				server 192.168.2.200:80;
			}
			server {
				listen 80;
				server_name localhost;
				location  / {
					proxy_pass  http://servers;
					root  html
					index  index.html  index.htm;
				}
			}
		}
		:wq
		/usr/local/nginx/sbin/nginx
		echo  "/usr/local/nginx/sbin/nginx"  >> /etc/rc.local
		iptables  -F
		setenforce  0

	2）客户端访问测试：
		http://192.168.4.5/test.php

		测试健康检查功能：
			将web1的nginx关闭后访问代理服务器
			192.168.4.5/test.php
			将web1的nginx启动后访问代理服务器
			192.168.4.5/test.php

	3）配置 upstream 集群池属性
		weight：设置服务器权重值，默认值为1
		max_fails：设置最大失败次数
		fail_timeout：设置失败超时时间，单位为秒
		down：标记服务器已关机，不参与集群调度
		
		vim  /usr/local/nginx/conf/nginx.conf
		http  {
			upstream  servers {
				server 192.168.2.100:80  weight=2 max_fails=1 fail_timeout=20;
				server 192.168.2.200:80;
			}
			server {
				listen 80;
				server_name localhost;
				location  / {
					proxy_pass  http://servers;
					root  html
					index  index.html  index.htm;
				}
			}
		}
		:wq

		访问测试：
			http://192.168.4.5/test.php

	4）ip_hash ，相同客户端访问相同服务器
		vim  /usr/local/nginx/conf/nginx.conf
		http  {
			upstream  servers {
				ip_hash;
				server 192.168.2.100:80  weight=2 max_fails=1 fail_timeout=20;
				server 192.168.2.200:80;
			}
			server {
				listen 80;
				server_name localhost;
				location  / {
					proxy_pass  http://servers;
					root  html
					index  index.html  index.htm;
				}
			}
		}
		:wq

3、WordPress 代码数据迁移
	1）在 proxy 上部署NFS
		yum  -y  install  nfs-utils
		mkdir  /web_share
		vim  /etc/exports
		/web_share  192.168.2.*(rw)
		systemctl  start   rpcbind  nfs
		systemctl  enable  rpcbind  nfs
		iptables  -F

	2）web1上备份网页数据，拷贝至proxy，解压至nfs共享目录
		web1:
			cd  /usr/local/nginx
			tar  -zcpf  html.tar.gz  html
			scp  html.tar.gz  192.168.2.5:/web_share
			
		proxy:
			cd  /web_share
			tar  -xf  html.tar.gz

	3）web1和web2挂载nfs共享目录（web1和web2相同操作）
		yum  -y  install  nfs-utils
		vim  /etc/fstab
		192.168.2.5:/web_share/html  /usr/local/nginx/html  nfs   defaults,_netdev  0  0
		mount  -a
		df  -h
	
	4）web2上创建数据库，添加数据库账户并授权
			mysql
			create  database  wordpress  character  set  utf8mb4;
			grant  all  on  wordpress.*  to  wordpress@'localhost'  identified  by  'wordpress';
			flush  privileges;
			exit

	5）客户端测试结果
		http://192.168.4.5



4、Nginx 四层代理
	1）需要ngx_stream_core_module模块
		使用 --with-stream开启该模块
             配置upsteam集群
              proxy_pass调用集群服务器

	2）安装 stream 模块（proxy上操作）
		/usr/local/nginx/sbin/nginx  -s  stop
		rm  -rf  /usr/local/nginx
		yum  -y  install  gcc  pcre-devel  openssl-devel
		tar  -xf   nginx-1.17.6.tar.gz
		cd  nginx-1.17.6
		./configure  --with-http_ssl_module  --with-stream
		make  &&  make  install

	3）修改Nginx配置，实现ssh四层代理
		vim  /usr/local/nginx/conf/nginx.conf
		stream {
			upstream  backend {
				server 192.168.2.100:22;
				server 192.168.2.200:22;
			}
			server {
				listen 12345;
				proxy_pass  backend;
			}
		}
		http {
		... ...
		}
		:wq
		/usr/local/nginx/sbin/nginx
		iptables  -F
		setenforce  0

	4）客户端测试
		使用xshell远程连接192.168.4.5的12345端口
		ssh  192.168.4.5  12345


5、Nginx 优化方案（上）
	1）自定义错误页面（web1上做）
		vim  /usr/local/nginx/conf/nginx.conf
		http {
			server {
				error_page 404  /404.html;
				.... ..
			}	
		}
		umount  /usr/local/nginx/html
		echo  "ni fang wen  de ye mian bu cun zai ，qing chang shi qi ta cao zuo!" > /usr/local/nginx/html/404.html
		/usr/local/nginx/sbin/nginx  -s  reload
			
		客户端测试：
			访问一个不存在的页面
			http://192.168.2.100/xxxxx	

				
	2）Nginx 状态页面
		安装status模块
			--with-http_stub_status_module开启模块功能
			可以查看Nginx连接数等信息
		
		在web1上操作：
			rm  -rf  
			cd   /root/lnmp_soft/
			tar  -xf   nginx-1.17.6.tar.gz
			cd  nginx-1.17.6
			./configure  --with-http_ssl_module  --with-http_stub_status_module
			make
			mv  /usr/local/nginx/sbin/nginx  /usr/local/nginx/sbin/nginx.old
			cp  objs/nginx   /usr/local/nginx/sbin/
			killall  nginx
			/usr/local/nginx/sbin/nginx

			vim  /usr/local/nginx/conf/nginx.conf
			server {
			... ...
				location  /status {
					stub_status on;			
				}
			... ...
			}
			:wq
			/usr/local/nginx/sbin/nginx  -s  reload

			客户机测试：
				http://192.168.2.100/status
			
			状态信息：
				Active  connections：当前活动的连接数量
				Accepts：已经接受客户端的连接总数量
				Handled：已经处理客户端的连接总数量
					一般与accepts一致，除非服务器限制了连接数量
				Requests：客户端发送请求数量
				Reading：当前服务器正在读取客户端请求头的数量
				Writing：当前服务器正在写响应信息的数量
				Waiting：当前多少客户端在等待服务器的响应

		

	